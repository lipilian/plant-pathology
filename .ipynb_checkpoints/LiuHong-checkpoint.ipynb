{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Pathology 2020\n",
    "\n",
    "- **v1**: Starter code\n",
    "- **v4**: 5-Folds CV. The gap between local and public score seems a bit high, probably because of the small number of validation samples. I added 5-folds (for now, simple k-fold) CV to see whether it reduces the difference. \n",
    "- **v5**: More augmentations. I try to train for more epochs. To prevent overfitting, I added more augmentations.\n",
    "\n",
    "|**Version**|**Net**|**#Folds**|**#Epochs**|**Local LB**|**Public LB**|**Notes**|\n",
    "|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|\n",
    "|v1| Resnet-18 | 1| 10| 0.972| 0.923|Starter code|\n",
    "|v4| Resnet-18 | 5| 5| 0.950 | 0.941 |5-folds CV|\n",
    "|v5| Resnet-18 | 5| 10| n.a. | n.a. |More augmentations|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'albumentations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9f18450771a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0malbumentations\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'albumentations'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "__print__ = print\n",
    "\n",
    "def print(string):\n",
    "    os.system(f'echo \\\"{string}\\\"')\n",
    "    __print__(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_INPUT = '/kaggle/input/plant-pathology-2020-fgvc7'\n",
    "\n",
    "SEED = 42\n",
    "N_FOLDS = 5\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transforms=None):\n",
    "    \n",
    "        self.df = df\n",
    "        self.transforms=transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_src = DIR_INPUT + '/images/' + self.df.loc[idx, 'image_id'] + '.jpg'\n",
    "        # print(image_src)\n",
    "        image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        labels = self.df.loc[idx, ['healthy', 'multiple_diseases', 'rust', 'scab']].values\n",
    "        labels = torch.from_numpy(labels.astype(np.int8))\n",
    "        labels = labels.unsqueeze(-1)\n",
    "        \n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=image)\n",
    "            image = transformed['image']\n",
    "\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = torchvision.models.resnet18(pretrained=True)\n",
    "        \n",
    "        in_features = self.backbone.fc.in_features\n",
    "        \n",
    "        self.logit = nn.ModuleList(\n",
    "            [nn.Linear(in_features, c) for c in num_classes]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, C, H, W = x.shape\n",
    "        \n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "        \n",
    "        x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n",
    "        x = F.dropout(x, 0.25, self.training)\n",
    "\n",
    "        logit = [l(x) for l in self.logit]\n",
    "\n",
    "        return logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = A.Compose([\n",
    "    A.RandomResizedCrop(height=256, width=256, p=1.0),\n",
    "    A.Flip(),\n",
    "    A.ShiftScaleRotate(rotate_limit=1.0, p=0.8),\n",
    "\n",
    "    # Pixels\n",
    "    A.OneOf([\n",
    "        A.IAAEmboss(p=1.0),\n",
    "        A.IAASharpen(p=1.0),\n",
    "        A.Blur(p=1.0),\n",
    "    ], p=0.5),\n",
    "\n",
    "    # Affine\n",
    "    A.OneOf([\n",
    "        A.ElasticTransform(p=1.0),\n",
    "        A.IAAPiecewiseAffine(p=1.0)\n",
    "    ], p=0.5),\n",
    "\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "])\n",
    "\n",
    "transforms_valid = A.Compose([\n",
    "    A.Resize(height=256, width=256, p=1.0),\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(DIR_INPUT + '/sample_submission.csv')\n",
    "submission_df.iloc[:, 1:] = 0\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = PlantDataset(df=submission_df, transforms=transforms_valid)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DIR_INPUT + '/train.csv')\n",
    "train_labels = train_df.iloc[:, 1:].values\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "oof_preds = np.zeros((train_df.shape[0], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained weights.\n",
    "model = PlantModel(num_classes=[1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_fold(model, dataloader_train, dataloader_valid):\n",
    "    \n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        print('  Epoch {}/{}'.format(epoch + 1, N_EPOCHS))\n",
    "        print('  ' + ('-' * 20))\n",
    "\n",
    "        model.train()\n",
    "        tr_loss = 0\n",
    "\n",
    "        for step, batch in enumerate(dataloader_train):\n",
    "\n",
    "            images = batch[0]\n",
    "            labels = batch[1]\n",
    "\n",
    "            images = images.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            losses = []\n",
    "            for i in range(4):\n",
    "                losses.append(criterion(outputs[i], labels[:, i]))\n",
    "\n",
    "            # weights: [1.0, 1.0, 1.0, 1.0]\n",
    "            loss = losses[0] + losses[1] + losses[2] + losses[3]\n",
    "            loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds = None\n",
    "        val_labels = None\n",
    "\n",
    "        for step, batch in enumerate(dataloader_valid):\n",
    "\n",
    "            images = batch[0]\n",
    "            labels = batch[1]\n",
    "\n",
    "            if val_labels is None:\n",
    "                val_labels = labels.clone().squeeze(-1)\n",
    "            else:\n",
    "                val_labels = torch.cat((val_labels, labels.squeeze(-1)), dim=0)\n",
    "\n",
    "            images = images.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "\n",
    "                losses = []\n",
    "                for i in range(4):\n",
    "                    losses.append(criterion(outputs[i], labels[:, i]))\n",
    "\n",
    "                # weights: [1.0, 1.0, 1.0, 1.0]\n",
    "                loss = losses[0] + losses[1] + losses[2] + losses[3]\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = torch.sigmoid(torch.stack(outputs).permute(1, 0, 2).cpu().squeeze(-1))\n",
    "\n",
    "                if val_preds is None:\n",
    "                    val_preds = preds\n",
    "                else:\n",
    "                    val_preds = torch.cat((val_preds, preds), dim=0)\n",
    "\n",
    "\n",
    "        print('  Training Loss: {:.4f}'.format(tr_loss / len(dataloader_train)))\n",
    "        print('  Validation Loss: {:.4f}'.format(val_loss / len(dataloader_valid)))\n",
    "        print('  Epoch score: {:.4f}'.format(roc_auc_score(val_labels, val_preds, average='macro')))\n",
    "        print('')\n",
    "\n",
    "    return val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df)):\n",
    "    print(\"Fold {}/{}\".format(i_fold, N_FOLDS - 1))\n",
    "    print(\"=\" * 20)\n",
    "    print(\"\")\n",
    "\n",
    "    valid = train_df.iloc[valid_idx]\n",
    "    valid.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    train = train_df.iloc[train_idx]\n",
    "    train.reset_index(drop=True, inplace=True)    \n",
    "    \n",
    "\n",
    "    dataset_train = PlantDataset(df=train, transforms=transforms_train)\n",
    "    dataset_valid = PlantDataset(df=valid, transforms=transforms_valid)\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)\n",
    "    dataloader_valid = DataLoader(dataset_valid, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    model = PlantModel(num_classes=[1, 1, 1, 1])\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    plist = [{'params': model.parameters(), 'lr': 5e-5}]\n",
    "    optimizer = optim.Adam(plist, lr=5e-5)\n",
    "    \n",
    "    val_preds = train_one_fold(model, dataloader_train, dataloader_valid)\n",
    "    oof_preds[valid_idx, :] = val_preds.numpy()\n",
    "    \n",
    "    print(\"  Predicting test set...\")\n",
    "    print(\"\")\n",
    "\n",
    "    model.eval()\n",
    "    test_preds = None\n",
    "\n",
    "    for step, batch in enumerate(dataloader_test):\n",
    "\n",
    "        images = batch[0]\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "\n",
    "            preds = torch.sigmoid(torch.stack(outputs).permute(1, 0, 2).cpu().squeeze(-1))\n",
    "\n",
    "            if test_preds is None:\n",
    "                test_preds = preds\n",
    "            else:\n",
    "                test_preds = torch.cat((test_preds, preds), dim=0)\n",
    "                \n",
    "    \n",
    "    submission_df[['healthy', 'multiple_diseases', 'rust', 'scab']] += test_preds.numpy() / N_FOLDS\n",
    "\n",
    "print(\"5-Folds CV score: {:.4f}\".format(roc_auc_score(train_labels, oof_preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
